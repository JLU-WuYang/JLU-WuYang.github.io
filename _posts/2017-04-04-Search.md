---
layout: post
title: 搜索引擎
description: "搜索引擎"
modified: 2016-12-12
tags: [搜索引擎]
image:
  feature: abstract-2.jpg
  credit: dargadgetz
  creditlink: http://www.dargadgetz.com/ios-7-abstract-wallpaper-pack-for-iphone-5-and-ipod-touch-retina/
---

搜索引擎

前期：
1. 爬虫
2. 提取标题
3. 提取内容
4. 对标题、内容进行分词
5. 对每个网页建立正向索引

   - 网页ID
     - 标题：
       - 词1：词1出现的数量
       - 词2：词2出现的数量
       - ..............
     - 内容：
       - 词1：词1出现的数量
       - 词2：词2出现的数量
       - ..............
     - 超链接
       - 词1：词1出现的数量
       - 词2：词2出现的数量
       - ..............

6. 对网页与词建立倒排索引
   
   - 词：
     - 网页ID 1
     - 网页ID 2
     - .......

响应：
1. 对用户输入内容进行分词
2. 根据分词结果得到待选集（如各词ID集的交集）
3. 对待选集中各文档进行排序（PageRank算法或自定义算法）
4. 根据排序结果的每个文档进行显示

   - 搜索词红色显示
   - 文档（网页）摘要
   - 以合适方式展示

5. 显示结果的分页

难点：
1. 爬虫

   - 来源：吉大各部门（学院）网站、相关公众号、吉大燕子
   - 措施：部分网站有反爬措施需调小频率约2次/秒

2. 分词

   - 问题：用jieba分词会产生一些不正确的分词方式
   - 解决：
     - 增加吉林大学相关字典 如吉大一院
     - 增加停用词如标点符号、无意义词汇

3. PageRank算法

  - 问题：该算法需进行超大矩阵乘法运算，内存不足
  - 解决：根据矩阵分块乘法原理编写了BlockMatrix

相关实现细节：
1. 吉林大学oa与首页都有相关网站超链接

   - 我使用限深度为10的宽度优先遍历进行爬取
   - 限定站内爬取可通过判断网址中域名部分来完成
   - 限定只爬网页可根据网页中最后的后缀名来判断，如过滤掉*.gif,*.png,*.jpg文件

2. 网页具体爬取

   - 标题找title
   - 字符编码找charset（用正则得到该网页的字符编码，一般为gbk gb2312）
   - 内容找\<p>\</p>之间内容 和 \<a>\</a>中内容。另，根据超链接可使用PageRank。
   - 具体网页可以进行特定优化

3. 排序算法

   - 由于使用PageRank算法效果不好。故我采用自定义排序算法。打分算法：若命中标题得10分/个，
     命中内容3分/个，命中超链接5分/个。分越高排名越高。

4. 搜索词红色显示

   - 从后台返回时将搜索词替换下来，替换成带标签得内容

5. 文档摘要
  
   - 简单实现一下。找到有搜索词得句子。将句子用...连接起来（若较多只取前三个）

可提升点：
- 爬虫更多来源（如贴吧）
- 内容提取（不够全）
- 排序算法（缺点是只要无脑重复关键词就能上升）
- 文档摘要

总结：我最后实现得是可维护、简单爬虫。我用Spider模块，若有更新则爬取否则不爬取。爬虫后更新正向索引
和倒排索引。

展望：
- 基于旧项目加入知识图谱相关内容建立问答系统。如图书馆几点关门？三点
- 基于旧项目与现有搜索引擎建立元搜索引擎 
   
